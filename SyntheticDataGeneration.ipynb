{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2444a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal, getcontext\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import curve_fit\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "538169c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 132)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m132\u001b[0m\n\u001b[1;33m    try:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "def find_primes(number_of_sets,lenght_of_sets):\n",
    "    \"\"\"\n",
    "    Generates a dictionary containing for each one of its entries a list of prime numbers as intergers\n",
    "    \n",
    "    number_of_sets == number of entries to be placed on the output dictionary as an int value\n",
    "    lenght_of_sets == lenght of each list corresponding to each dicitionay entrie as an int value\n",
    "    \"\"\"\n",
    "    #strts test at number 4\n",
    "    number_tested = 3\n",
    "    sets_disc = {}\n",
    "    #store sets of primes for the output\n",
    "    sets_disc[0] = [2,3]\n",
    "    #store all primes to check for future primes\n",
    "    all_primes = [2,3]\n",
    "    #restrains for the number of sets desired\n",
    "    for i in range (number_of_sets):\n",
    "        #check to create an empty list if not first dictionary key\n",
    "        if i >= 1:\n",
    "                sets_disc[i] = []\n",
    "        #restrains for the number of elements in each desired set\n",
    "        while len(sets_disc[i]) < lenght_of_sets:\n",
    "            #actual cicle to find prime numbers\n",
    "            number_tested += 1\n",
    "            checker = 0\n",
    "            for k in all_primes:\n",
    "                if number_tested % k != 0:\n",
    "                    pass\n",
    "                else:\n",
    "                    checker = 1\n",
    "                    break\n",
    "            if checker == 0:\n",
    "                all_primes.append(number_tested)\n",
    "                sets_disc[i].append(number_tested)\n",
    "        \n",
    "    return(sets_disc)\n",
    "             \n",
    "#use prime numbers to generate time-series wuth desired length\n",
    "def get_inputs(length, prime_list):\n",
    "    \"\"\"\n",
    "    Calculation of a square root of prime numbers, generating irrational values, to create time-series\n",
    "    by using the individual decimal characters of the result\n",
    "    \n",
    "    length = length of the deseired final time-series as an int value\n",
    "    prime_list = list of prime numbers (as ints) to be used on time-series generation\n",
    "    \n",
    "    \"\"\"\n",
    "    n_of_inputs = len(prime_list)\n",
    "    #generates 2D array for individual sqr of prime numbers\n",
    "    array_of_inputs = np.zeros((n_of_inputs,length))\n",
    "    #required to generate sqrt with desired decimal numbers\n",
    "    getcontext().prec = length + 9\n",
    "    \n",
    "    for n in range(n_of_inputs):\n",
    "        sqrt = Decimal(prime_list[n]).sqrt()\n",
    "        #takes values after the 10 first to avoid including the decimal separator\n",
    "        sqrt_str = str(sqrt)[10:]\n",
    "        lista = [int(i) for i in sqrt_str]\n",
    "        array_of_inputs[n] = np.array(lista)\n",
    "    \n",
    "    #generate a singular array to be the main object of operations as a time-series\n",
    "    singular_array = array_of_inputs[0]\n",
    "    #sums and subtractions to allow for semi random values that are still dependent from the original sqrt values\n",
    "    for n in range(1,len(array_of_inputs[:,0])):\n",
    "        if n % 2 != 0:\n",
    "            singular_array = singular_array - array_of_inputs[n]\n",
    "        else:\n",
    "            singular_array = singular_array + array_of_inputs[n]\n",
    "    \n",
    "    return array_of_inputs, singular_array\n",
    "\n",
    "\n",
    "\n",
    "#gets cossine both for single array or 2D array\n",
    "def get_cossine(scaling_factor,n_of_periods,start_point_oscilation,array_of_inputs,noise_level):\n",
    "    \"\"\"\n",
    "    Generates a cossine wave with a noise generated by a list, with customizable scale, number of periods and oscilation of the starting point \n",
    "    \n",
    "    scaling_factor = float type to indicate the amplitude of the wave\n",
    "    n_of_periods = desired number of periods for every 365 datapoints as an integer\n",
    "    start_point_oscilation = oscilation on the inintial wave value as a float value below 1\n",
    "    array_of_inputs = array either 1D or 2D to be used as noise for the time-series as float\n",
    "    noise_level = intendity on wich the array_of_inputs used as noise will affect the wave\n",
    "    \n",
    "    \"\"\"\n",
    "    #check if the array_of_inputs has 2 dimensions\n",
    "    try:\n",
    "        array_of_inputs.shape[1]\n",
    "        array_type = \"array_of_inputs\"\n",
    "    except:\n",
    "        array_type = \"singular_array\"\n",
    "        \n",
    "    if array_type == \"array_of_inputs\":\n",
    "        length = len(array_of_inputs[0])\n",
    "        oscilation = int(start_point_oscilation*length)\n",
    "        array_of_cossines = np.zeros((array_of_inputs.shape[0],length))\n",
    "        #frequency atenuation to obtain desired periods\n",
    "        f_attenuation = length/(n_of_periods*length//365)/6.29\n",
    "        \n",
    "        for n in (range(array_of_inputs.shape[0])):\n",
    "            #generates a normalization of the generated noise for the wave\n",
    "            input_norm_Cos = [i*noise_level/np.pi for i in array_of_inputs[n]]\n",
    "            cossine = scaling_factor*np.cos(np.arange(sum(array_of_inputs[n,:oscilation]),length+sum(array_of_inputs[n,:oscilation]))/f_attenuation-input_norm_Cos)\n",
    "            array_of_cossines[n,:] = cossine\n",
    "    \n",
    "    #same process but for a 1D array\n",
    "    if array_type == \"singular_array\":\n",
    "        length = len(array_of_inputs)\n",
    "        oscilation = int(start_point_oscilation*length)\n",
    "        array_of_cossines = np.zeros((length))\n",
    "        f_attenuation = length/(n_of_periods*length//365)/6.29\n",
    "        input_norm_Cos = [i*noise_level/np.pi for i in array_of_inputs]\n",
    "        cossine = scaling_factor*np.cos(np.arange(sum(array_of_inputs[:oscilation]),length+sum(array_of_inputs[:oscilation]))/f_attenuation-input_norm_Cos)\n",
    "        array_of_cossines = cossine\n",
    "                \n",
    "    return array_of_cossines \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_sine(scaling_factor,n_of_periods,start_point_oscilation,noise_level,array_of_inputs):\n",
    "     \"\"\"\n",
    "    Generates a sine wave with a noise generated by a list, with customizable scale, number of periods and oscilation of the starting point \n",
    "    \n",
    "    scaling_factor = float type to indicate the amplitude of the wave\n",
    "    n_of_periods = desired number of periods for every 365 datapoints as an integer\n",
    "    start_point_oscilation = oscilation on the inintial wave value as a float value below 1\n",
    "    array_of_inputs = array either 1D or 2D to be used as noise for the time-series as float\n",
    "    noise_level = intendity on wich the array_of_inputs used as noise will affect the wave\n",
    "    \n",
    "    \"\"\"\n",
    "    #check if the array_of_inputs has 2 dimensions\n",
    "    try:\n",
    "        array_of_inputs.shape[1]\n",
    "        array_type = \"array_of_inputs\"\n",
    "    except:\n",
    "        array_type = \"singular_array\"\n",
    "        \n",
    "    if array_type == \"array_of_inputs\":\n",
    "        length = len(array_of_inputs[0])\n",
    "        oscilation = int(start_point_oscilation*length)\n",
    "        array_of_sines = np.zeros((array_of_inputs.shape[0],length))\n",
    "        #frequency atenuation to obtain desired periods\n",
    "        f_attenuation = length/(n_of_periods*length//365)/6.29\n",
    "        \n",
    "        for n in (range(array_of_inputs.shape[0])):\n",
    "            #generates a normalization of the generated noise for the wave\n",
    "            input_norm_sin = [i*noise_level/np.pi for i in array_of_inputs[n]]\n",
    "            cossine = scaling_factor*np.cos(np.arange(sum(array_of_inputs[n,:oscilation]),length+sum(array_of_inputs[n,:oscilation]))/f_attenuation-input_norm_sin)\n",
    "            array_of_sines[n,:] = cossine\n",
    "    \n",
    "    #same process but for a 1D array\n",
    "    if array_type == \"singular_array\":\n",
    "        length = len(array_of_inputs)\n",
    "        oscilation = int(start_point_oscilation*length)\n",
    "        array_of_sines = np.zeros((length))\n",
    "        f_attenuation = length/(n_of_periods*length//365)/6.29\n",
    "        input_norm_sin = [i*noise_level/np.pi for i in array_of_inputs]\n",
    "        cossine = scaling_factor*np.cos(np.arange(sum(array_of_inputs[:oscilation]),length+sum(array_of_inputs[:oscilation]))/f_attenuation-input_norm_sin)\n",
    "        array_of_sines = cossine\n",
    "                \n",
    "    return array_of_sines \n",
    "\n",
    "\n",
    "\n",
    "def get_ln(list_of_inputs, max_value):\n",
    "    \"\"\"\n",
    "    Return the ln of the list resulting of the partial sums of another list\n",
    "    \n",
    "    list_of_inputs = values to be used on summation and ln value generation as float or int\n",
    "    max_value = upper bound for the otput list value as float or int\n",
    "    \"\"\"\n",
    "    list_of_sums=[]\n",
    "    length = len(list_of_inputs)\n",
    "    sums_n= 0\n",
    "    for n in range(length):\n",
    "        sums_n += abs(list_of_inputs[n])            \n",
    "        list_of_sums.append(np.log((sums_n)))\n",
    "    list_of_sums  = [max_value*i/(np.max(list_of_sums)) for i in list_of_sums]\n",
    "    return list_of_sums\n",
    "\n",
    "def linear_trend(list_of_inputs, max_value):\n",
    "    \"\"\"\n",
    "    Return the list resulting of the partial sums of another list\n",
    "    \n",
    "    list_of_inputs = values to be used on summation and ln value generation as float or int\n",
    "    max_value = upper bound for the otput list value as float or int\n",
    "    \"\"\"\n",
    "    list_of_sums=[]\n",
    "    length = len(list_of_inputs)\n",
    "    sums_n= 0\n",
    "    for n in range(len(list_of_inputs)):\n",
    "        sums_n += list_of_inputs[n]\n",
    "        list_of_sums.append(sums_n)\n",
    "    list_of_sums = [max_value*i/(np.max(list_of_sums)-np.min(list_of_sums)) for i in list_of_sums]\n",
    "    return list_of_sums\n",
    "\n",
    "\n",
    "def get_promo_effects(data,normal_behaviour):\n",
    "    \"\"\"\n",
    "    Generates campaign effects on a time series by using statistical analysis over another time-series,\n",
    "    returns positinos of promotional effects and altered time-series\n",
    "    \n",
    "    data = time-series used for statistical analysis\n",
    "    normal_behaviour = time-series to have campaign effects\n",
    "    \"\"\"\n",
    "    singular_list = data\n",
    "    \n",
    "    index_under= {}\n",
    "    index_above={}\n",
    "\n",
    "    # Create a histogram\n",
    "    hist, bin_edges = np.histogram(data, bins=80, density=True)\n",
    "\n",
    "    # Calculate the bin centers\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "    # Define the normal distribution function\n",
    "    def normal_distribution(x, mu, sigma):\n",
    "        return norm.pdf(x, mu, sigma)\n",
    "\n",
    "    # Fit the normal distribution parameters to the data\n",
    "    params, covariance = curve_fit(normal_distribution, bin_centers, hist, p0=[0, 1])\n",
    "\n",
    "    # Extract the mean and standard deviation from the fitted parameters\n",
    "    mu, sigma = params\n",
    "    normal_dist = norm(loc=mu, scale=sigma)\n",
    "\n",
    "    #quantiles representing \"bad sales\" or \"promotions\"\n",
    "    bad_sales = [0.075, 0.05, 0.025]\n",
    "\n",
    "    promotions = [0.925, 0.95, 0.975]\n",
    "\n",
    "    for i in range(3):\n",
    "        bad = bad_sales[i]\n",
    "        promo = promotions[i]\n",
    "        #gets index of values on time series above or under a set quantile threshold\n",
    "        quantile_promo = normal_dist.ppf(promo)\n",
    "        quantile_bad = normal_dist.ppf(bad)\n",
    "        indices_under_threshold = [index for index, value in enumerate(singular_list) if value < quantile_bad]\n",
    "        indices_above_threshold = [index for index, value in enumerate(singular_list) if value > quantile_promo]\n",
    "\n",
    "        index_under[i]= indices_under_threshold\n",
    "        index_above[i]= indices_above_threshold\n",
    "        #generates a smoothing profile for the cmapaign effect, both for increase and decrease\n",
    "        smoothing_bad1 = np.linspace(0.8,0.3,4)\n",
    "        smoothing_bad2 = np.linspace(0.4,0.8,3)\n",
    "\n",
    "        smoothing_promo1 = np.linspace(1.1,1.4,4)\n",
    "        smoothing_promo2 = np.linspace(1.3,1.1,3)\n",
    "\n",
    "        smoothing_bad = np.append(smoothing_bad1,smoothing_bad2)\n",
    "        smoothing_promo = np.append(smoothing_promo1,smoothing_promo2)\n",
    "        #apply the campaign effects on the time-series\n",
    "        for j in (indices_under_threshold):\n",
    "            for k in range(len(smoothing_promo)):\n",
    "                try:\n",
    "                    normal_behaviour[j+(k-2)] = normal_behaviour[j+(k-2)]*smoothing_bad[k]\n",
    "                    normal_behaviour[j+(k-2)] = normal_behaviour[j+(k-2)]*smoothing_promo[k]\n",
    "                except:\n",
    "                    pass\n",
    "    #get index of camapaigns individualy by strenght of campaign effect\n",
    "    index_under[0] = [value for value in index_under[0] if value not in index_under[1]]\n",
    "    index_under[1] = [value for value in index_under[1] if value not in index_under[2]]\n",
    "    \n",
    "    index_above[0] = [value for value in index_above[0] if value not in index_above[1]]\n",
    "    index_above[1] = [value for value in index_above[1] if value not in index_above[2]]\n",
    "\n",
    "    return index_under,index_above,normal_behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b10d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_series(numer_of_time_series, lenght_of_time_series):\n",
    "    \"\"\"\n",
    "    Aggregates all functions created to allow for the generation of a synthetic time-series\n",
    "    \n",
    "    numer_of_time_series = number of time-series desired, as an integer\n",
    "    lenght_of_time_series = length of each time-series as an integer\n",
    "    \"\"\"\n",
    "    #find_primes(number_of_sets,lenght_of_sets)\n",
    "    prime_dic_list=find_primes(numer_of_time_series,50)\n",
    "    exogenous_features = {}\n",
    "\n",
    "    for prime_list_number in prime_dic_list.keys(): \n",
    "        #get_inputs(length, prime_list)\n",
    "        inputs,singular_list = get_inputs(lenght_of_time_series,prime_dic_list[prime_list_number])\n",
    "        \n",
    "        #get_cossine(scaling_factor,n_of_periods,start_point_oscilation,array_of_inputs,noise_level)\n",
    "        cossine = get_cossine(0.6,4,0.1,0.15,singular_list)\n",
    "        #get_sine(scaling_factor,n_of_periods,start_point_oscilation,array_of_inputs,noise_level)\n",
    "        sine = get_sine(2,52,0.1,0.4,singular_list)\n",
    "        #get_ln(list_of_inputs, max_value):\n",
    "        logs = np.array(get_ln(singular_list,1))\n",
    "        #linear_trend(list_of_inputs, max_value):\n",
    "        linear = np.array(linear_trend(singular_list,10))\n",
    "        \n",
    "        exog_coss = get_cossine(1,4,0.1,1,inputs)\n",
    "        exog_sine = get_sine(0.6,52,0.1,0.4,inputs)\n",
    "        \n",
    "        trend = np.array(linear)+(0.8/np.array(logs))\n",
    "        normal_behaviour = abs(trend+sine+cossine)\n",
    "        \n",
    "        #get_promo_effects(data,normal_behaviour):\n",
    "        index_under,index_above,normal_behaviour = get_promo_effects(singular_list,normal_behaviour)\n",
    "        \n",
    "        \n",
    "        #using data to generated a csv file of a time-series with exogenous features\n",
    "        \n",
    "        exogenous_features['TGT'] = normal_behaviour\n",
    "        exogenous_features['singular_array'] = singular_list\n",
    "        for number_of_array in range(inputs.shape[0]):\n",
    "            exogenous_features[f'prime_sqr_n_{number_of_array}'] = inputs[number_of_array]\n",
    "            exogenous_features[f'sine_prime_sqr_n_{number_of_array}'] = exog_sine[number_of_array]\n",
    "            exogenous_features[f'coss_prime_sqr_n_{number_of_array}'] = exog_coss[number_of_array]\n",
    "            \n",
    "            \n",
    "        for strength in range(3):\n",
    "            exogenous_features[f'promotional_effect_strength_{strength}'] = np.zeros(lenght_of_time_series)    \n",
    "            exogenous_features[f'LowSakes_effect_strength_{strength}'] = np.zeros(lenght_of_time_series)  \n",
    "        \n",
    "            for position in index_under[strength]:\n",
    "                for i in range (3):\n",
    "                    try:\n",
    "                        exogenous_features[f'promotional_effect_strength_{strength}'][position-i] = 1\n",
    "                        exogenous_features[f'LowSales_effect_strength_{strength}'][position-i] = 1\n",
    "                    except:\n",
    "                        pass\n",
    "                \n",
    "        df = pd.DataFrame(exogenous_features)\n",
    "        os.makedirs('Synthetic_Datasets', exist_ok=True)\n",
    "        df.to_csv(f'Synthetic_Datasets/Data_number_{prime_list_number}.csv', index=False)\n",
    "        \n",
    "    \n",
    "    #shows the last time-series graph and dataframe for confirmation\n",
    "    plt.figure(figsize = (50,20))\n",
    "    plt.plot(np.arange(lenght_of_time_series),normal_behaviour)\n",
    "    plt.plot(np.arange(lenght_of_time_series),linear)\n",
    "    plt.plot(np.arange(lenght_of_time_series),trend)\n",
    "    plt.show()\n",
    "    \n",
    "    return (df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af39a7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_time_series(100,1095)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8211722a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
